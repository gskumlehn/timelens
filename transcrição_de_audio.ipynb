{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gskumlehn/timelens/blob/main/transcri%C3%A7%C3%A3o_de_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e25775",
      "metadata": {
        "id": "90e25775"
      },
      "source": [
        "# Transcrição com Whisper (OpenAI) — Colab\n",
        "\n",
        "**Como usar (passo a passo):**\n",
        "1. **Execute as células na ordem.**\n",
        "2. Na etapa de **upload**, selecione seu arquivo de áudio/vídeo (`.mp3`, `.wav`, `.m4a`, `.mp4` etc.).\n",
        "3. Opcional: troque o tamanho do modelo (`tiny`, `base`, `small`, `medium`, `large`) conforme velocidade/qualidade desejada.\n",
        "4. Rode a célula de **transcrição** e aguarde o texto no console.\n",
        "5. Se quiser salvar em arquivo `.txt`, use a célula opcional ao final.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c1c17f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c1c17f5",
        "outputId": "2eb56031-d9fe-457c-dc6a-d65419fea4b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/803.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# 1) Instalação das dependências\n",
        "!pip install -q openai-whisper\n",
        "!apt-get -y install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b642987",
      "metadata": {
        "id": "9b642987"
      },
      "outputs": [],
      "source": [
        "# 2) Upload do arquivo de áudio/vídeo\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "# Pegará o primeiro arquivo enviado; ajuste se enviar mais de um\n",
        "audio_file = list(uploaded.keys())[0]\n",
        "print(\"Arquivo recebido:\", audio_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2f67a72",
      "metadata": {
        "id": "e2f67a72"
      },
      "outputs": [],
      "source": [
        "# 3) Importa e carrega o modelo Whisper\n",
        "import whisper\n",
        "\n",
        "# Opções de modelo: tiny, base, small, medium, large\n",
        "# Quanto maior, melhor a qualidade e mais lento/maior uso de memória.\n",
        "MODEL_NAME = \"medium\"\n",
        "\n",
        "print(\"Carregando modelo:\", MODEL_NAME)\n",
        "model = whisper.load_model(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9962e49a",
      "metadata": {
        "id": "9962e49a"
      },
      "outputs": [],
      "source": [
        "# 4) Transcrição\n",
        "# Defina 'language' se quiser forçar o idioma (ex.: 'pt' para português).\n",
        "# Caso contrário, o Whisper tenta detectar automaticamente.\n",
        "result = model.transcribe(audio_file, language=\"pt\")\n",
        "print(\"\\n==== TRANSCRIÇÃO ====\")\n",
        "print(result[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a80caa10",
      "metadata": {
        "id": "a80caa10"
      },
      "outputs": [],
      "source": [
        "# 5) Salvar transcrição em arquivo .txt\n",
        "output_txt = \"transcricao.txt\"\n",
        "with open(output_txt, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result[\"text\"])\n",
        "\n",
        "print(\"Transcrição salva em:\", output_txt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
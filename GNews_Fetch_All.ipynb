{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gskumlehn/timelens/blob/main/GNews_Fetch_All.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxyJQIZuST3Y"
      },
      "source": [
        "# GNews → Excel (todas as páginas em uma aba)\n",
        "\n",
        "**Input único:** `query`.\n",
        "\n",
        "**Token:** o notebook lê o token da API do GNews a partir da variável de ambiente `GNEWS_TOKEN`.\n",
        "\n",
        "**Saída:** um arquivo `.xlsx` com todas as notícias de todas as páginas em uma única planilha e *download automático* no Colab.\n",
        "\n",
        "**Como usar no Colab:**\n",
        "1. Em *Runtime → Restart and run all* (ou execute célula a célula).\n",
        "2. Antes de executar a célula final, defina `GNEWS_TOKEN` no ambiente do Colab (ex.: `import os; os.environ['GNEWS_TOKEN']='SEU_TOKEN_AQUI'`).\n",
        "3. Informe a `query` no formulário e execute."
      ],
      "id": "CxyJQIZuST3Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "UYozRPjuST3a"
      },
      "source": [
        "# @title Instalações (se necessário)\n",
        "!pip -q install requests pandas openpyxl"
      ],
      "outputs": [],
      "execution_count": 4,
      "id": "UYozRPjuST3a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rFDibnwST3b",
        "outputId": "743d71f3-9460-4853-cef8-717d0b8a8d0b"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "GNEWS_TOKEN = \"1d4fbd4762fc0b33ddf1b0ba67fd7292\"\n",
        "BASE_URL = \"https://gnews.io/api/v4/search\"\n",
        "\n",
        "def _sanitize_filename(name: str) -> str:\n",
        "    name = re.sub(r\"\\s+\", \"_\", name.strip())\n",
        "    name = re.sub(r\"[^A-Za-z0-9._-]\", \"\", name)\n",
        "    return name[:150] or \"resultado\"\n",
        "\n",
        "def search_gnews(query, lang=\"pt\", country=\"br\", max_results=100, from_date=None, to_date=None, sort_by=\"publishedAt\", page=1):\n",
        "    API_KEY = GNEWS_TOKEN\n",
        "    if not API_KEY:\n",
        "        raise RuntimeError(\"Variável de ambiente GNEWS_TOKEN não definida.\")\n",
        "\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"token\": API_KEY,\n",
        "        \"lang\": lang,\n",
        "        \"in\": \"title,description,content\",\n",
        "        \"country\": country,\n",
        "        \"max\": max_results,\n",
        "        \"sortby\": sort_by,\n",
        "        \"page\": page,\n",
        "        \"expand\": \"content\",\n",
        "    }\n",
        "\n",
        "    if from_date:\n",
        "        params[\"from\"] = from_date\n",
        "    if to_date:\n",
        "        params[\"to\"] = to_date\n",
        "\n",
        "    resp = requests.get(BASE_URL, params=params, timeout=60)\n",
        "    resp.raise_for_status()\n",
        "    return resp.json()\n",
        "\n",
        "def fetch_and_save_all(query, lang=\"pt\", country=\"br\", max_per_page=100, from_date=None, to_date=None, sort_by=\"publishedAt\"):\n",
        "    ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    base = _sanitize_filename(query)\n",
        "    if from_date or to_date:\n",
        "        output_file = f\"{base}-from{from_date}-to{to_date}-{ts}.xlsx\"\n",
        "    else:\n",
        "        output_file = f\"{base}-{ts}.xlsx\"\n",
        "\n",
        "    dfs = []\n",
        "    page = 1\n",
        "    while True:\n",
        "        data = search_gnews(query, lang, country, max_per_page, from_date, to_date, sort_by, page)\n",
        "        articles = data.get(\"articles\", [])\n",
        "        if not articles:\n",
        "            break\n",
        "        dfs.append(pd.json_normalize(articles))\n",
        "        page += 1\n",
        "\n",
        "    if not dfs:\n",
        "        raise RuntimeError(\"Nenhuma notícia encontrada para a query informada.\")\n",
        "\n",
        "    all_df = pd.concat(dfs, ignore_index=True)\n",
        "    with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
        "        all_df.to_excel(writer, sheet_name=\"results\", index=False)\n",
        "\n",
        "    return output_file\n",
        "\n",
        "print(\"Pronto. Use a célula abaixo para rodar sua query.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pronto. Use a célula abaixo para rodar sua query.\n"
          ]
        }
      ],
      "execution_count": 5,
      "id": "1rFDibnwST3b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qnp9fCTlST3c",
        "outputId": "386bcf65-75f2-4f7b-9ed2-c12aa499f82a"
      },
      "source": [
        "# @title Rodar busca e baixar Excel\n",
        "query = \"Banco do Brasil\" # @param {type:\"string\"}\n",
        "lang = \"pt\"        # @param [\"pt\"]\n",
        "country = \"br\"     # @param [\"br\"]\n",
        "sort_by = \"publishedAt\"  # @param [\"publishedAt\", \"relevance\"]\n",
        "max_per_page = 100  # @param {type:\"integer\"}\n",
        "from_date = \"\\\"2025-08-04T12:00:00.000Z\\\"\"    # @param {type:\"string\"}\n",
        "to_date = \"\\\"2025-08-06T12:00:00.000Z\\\"\"      # @param {type:\"string\"}\n",
        "\n",
        "xlsx_path = fetch_and_save_all(\n",
        "    query=query,\n",
        "    lang=lang,\n",
        "    country=country,\n",
        "    max_per_page=max_per_page,\n",
        "    from_date=from_date,\n",
        "    to_date=to_date,\n",
        "    sort_by=sort_by,\n",
        ")\n",
        "print(\"Arquivo gerado:\", xlsx_path)\n",
        "files.download(xlsx_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivo gerado: Banco_do_Brasil-from\"2025-08-04T12:00:00.000Z\"-to\"2025-08-06T12:00:00.000Z\"-20250812-171920.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b9c5a2ff-e09b-41cd-bc23-585d6a40e96d\", \"Banco_do_Brasil-from\\\"2025-08-04T12:00:00.000Z\\\"-to\\\"2025-08-06T12:00:00.000Z\\\"-20250812-171920.xlsx\", 2188059)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "id": "Qnp9fCTlST3c"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}